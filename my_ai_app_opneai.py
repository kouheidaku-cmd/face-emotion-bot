# pythonã®ã‚µãƒ¼ãƒãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã‚‚ã‚ã‚‹
import cv2
import numpy as np
import base64
from fastapi import FastAPI, WebSocket
from fastapi.responses import FileResponse # è¿½åŠ ï¼šãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™ãŸã‚ã®æ©Ÿèƒ½
import json
import uvicorn
from openai import OpenAI # OpenAIã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«å¤‰æ›´
from dotenv import load_dotenv
import os
from pathlib import Path
from fastapi.staticfiles import StaticFiles # ã“ã‚Œã‚’è¿½åŠ 

app = FastAPI()

# ---------------------------- 1. è¨­å®š ----------------------------
current_dir = Path(__file__).parent.absolute()
env_path = current_dir / ".env"
load_dotenv(dotenv_path=env_path)
# ğŸ’¡ ã“ã‚Œã‚’è¿½åŠ ï¼ staticãƒ•ã‚©ãƒ«ãƒ€ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰è¦‹ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
app.mount("/static", StaticFiles(directory="static"), name="static")

# OpenAIç”¨ã®è¨­å®š
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY")) 
MODEL_NAME = "gpt-4o-mini" # ã‚³ã‚¹ãƒ‘æœ€å¼·ã®è»½é‡ãƒ¢ãƒ‡ãƒ«


# æ„Ÿæƒ…ãƒãƒƒãƒ—
EMOTION_DICT = {
    "angry": "æ€’ã‚Š", "disgust": "å«Œæ‚ª", "fear": "æã‚Œ",
    "happy": "å–œã³", "sad": "æ‚²ã—ã¿", "surprise": "é©šã", "neutral": "è‡ªç„¶ä½“"
}


chat_history=[]

# ç”»é¢ã‚’å‡ºã™ãŸã‚ã®è¨­å®š
@app.get("/")
async def get():
    return FileResponse('static/index.html')

# script.jsã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã«é€ã‚‹
@app.get("/script.js")
async def get_js():
    return FileResponse('static/script.js')

# WebSocket è§£æãƒ­ã‚¸ãƒƒã‚¯
@app.websocket("/ws/analyze")
async def websocket_endpoint(websocket: WebSocket):

    await websocket.accept()
    print("Client connected")
    try:
        #é€šä¿¡ãŒå§‹ã¾ã£ã¦ä¸€å›ç›®ã®é¡”å†™çœŸã®é€ä¿¡ã®éš›ã«ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸè¨­å®šã‚’è¡Œã†
        raw_data = await websocket.receive_text()

        while True:
            raw_data = await websocket.receive_text()
            data = json.loads(raw_data)

            if data["type"]=="chat":
                response_json=make_response(data)
                # ãƒ–ãƒ©ã‚¦ã‚¶ã«è¿”ç­”ã‚’é€ä¿¡
                await websocket.send_text(json.dumps({
                    "status":"chat_response",
                    "reply":response_json["reply"],
                    "ai_emotion":response_json["ai_emotion"]
                }))
    except Exception as e:
        print(f"Disconnected: {e}")


#ãƒãƒ£ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®è¿”ä¿¡
def make_response(data):
    global chat_history
    user_message=data["value"]
    #ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜
    chat_history.append({"role":"user","content":f"{user_message}"})
    print(f"Chat message received: {user_message}")
    
    # OpenAIç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦
    prompt = (
                f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼š{user_message}\n"
                "ä¼šè©±ã®æµã‚Œã‚’ã‚¹ãƒ ãƒ¼ã‚ºã«ã™ã‚‹ãŸã‚è¿”ç­”ã®ç”Ÿæˆã¯ã§ãã‚‹ã ã‘æ—©ãè¡Œã£ã¦ãã ã•ã„ã€‚\n"
                "ã¾ãŸã€è©±ã—è¨€è‘‰ã‚’æƒ³å®šã—ç®‡æ¡æ›¸ããªã©ã¯æ§ãˆã¦ãã ã•ã„\n"
                "ä»¥ä¸‹ã®JSONå½¢å¼ã§è¿”ç­”ã—ã¦ãã ã•ã„ï¼š\n"
                "{ \"reply\": \"è¿”ç­”\", \"ai_emotion\": \"å–œã³/æ‚²ã—ã¿/é©šã/è‡ªç„¶ä½“/æ€’ã‚Š/å«Œæ‚ª/æã‚Œ\" }\n" 
                "æ³¨æ„ç‚¹ã¨ã—ã¦ai_emotionã«ã¯å¿ƒé…ã¯å«ã¾ã‚Œã¦ãŠã‚Šã¾ã›ã‚“"
            )
    
    current_messages = chat_history + [{"role": "user", "content": prompt}]

    # OpenAI APIã‚’å‘¼ã³å‡ºã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=current_messages,#ã“ã®æ™‚å±¥æ­´ã‚‚ä¸€ç·’ã«æ¸¡ã™
        response_format={"type": "json_object"}
    )
    
    response_json=json.loads(response.choices[0].message.content)
    print(f"AI Response: {response_json}")
    #chat_historyã®æ›´æ–°
    chat_history.append({"role":"assistant","content":response_json["reply"]})
    # å±¥æ­´ãŒé•·ããªã‚Šã™ãã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã§ã€åˆæœŸè¨­å®šã¯æ®‹ã—ã¦ç›´è¿‘10ä»¶ãã‚‰ã„ã«çµã‚‹ã®ãŒä¸€èˆ¬çš„
    if len(chat_history) > 11:
        chat_history = [chat_history[0]] +[chat_history[1]] + chat_history[-10:]
    return response_json


# pythonã‚µãƒ¼ãƒã®ç«‹ã¡ä¸Šã’
if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)