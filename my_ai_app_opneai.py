# pythonã®ã‚µãƒ¼ãƒãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã‚‚ã‚ã‚‹
import cv2
import numpy as np
import base64
from fastapi import FastAPI, WebSocket
from fastapi.responses import FileResponse # è¿½åŠ ï¼šãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™ãŸã‚ã®æ©Ÿèƒ½
from deepface import DeepFace
import json
import uvicorn
from openai import OpenAI # OpenAIã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«å¤‰æ›´
from dotenv import load_dotenv
import os
from pathlib import Path
from fastapi.staticfiles import StaticFiles # ã“ã‚Œã‚’è¿½åŠ 

app = FastAPI()

# ---------------------------- 1. è¨­å®š ----------------------------
current_dir = Path(__file__).parent.absolute()
env_path = current_dir / ".env"
load_dotenv(dotenv_path=env_path)
# ğŸ’¡ ã“ã‚Œã‚’è¿½åŠ ï¼ staticãƒ•ã‚©ãƒ«ãƒ€ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰è¦‹ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
app.mount("/static", StaticFiles(directory="static"), name="static")

# OpenAIç”¨ã®è¨­å®š
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY")) 
MODEL_NAME = "gpt-4o-mini" # ã‚³ã‚¹ãƒ‘æœ€å¼·ã®è»½é‡ãƒ¢ãƒ‡ãƒ«


# æ„Ÿæƒ…ãƒãƒƒãƒ—
EMOTION_DICT = {
    "angry": "æ€’ã‚Š", "disgust": "å«Œæ‚ª", "fear": "æã‚Œ",
    "happy": "å–œã³", "sad": "æ‚²ã—ã¿", "surprise": "é©šã", "neutral": "è‡ªç„¶ä½“"
}


chat_history=[]

# ç”»é¢ã‚’å‡ºã™ãŸã‚ã®è¨­å®š
@app.get("/")
async def get():
    return FileResponse('static/index.html')

# script.jsã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã«é€ã‚‹
@app.get("/script.js")
async def get_js():
    return FileResponse('static/script.js')

# WebSocket è§£æãƒ­ã‚¸ãƒƒã‚¯
@app.websocket("/ws/analyze")
async def websocket_endpoint(websocket: WebSocket):

    await websocket.accept()
    print("Client connected")
    try:
        #é€šä¿¡ãŒå§‹ã¾ã£ã¦ä¸€å›ç›®ã®é¡”å†™çœŸã®é€ä¿¡ã®éš›ã«ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸè¨­å®šã‚’è¡Œã†
        raw_data = await websocket.receive_text()
        first_contact(raw_data)

        while True:
            detected_emotion="ä¸æ˜"
            raw_data = await websocket.receive_text()
            data = json.loads(raw_data)

            #-----------------ç”»åƒãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†------------------
            if data["type"]=="image":
                try:
                    encoded_data = data["value"].split(',')[1]
                    nparr = np.frombuffer(base64.b64decode(encoded_data), np.uint8)
                    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                    results = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)
                    emotion_en = results[0]['dominant_emotion']
                    detected_emotion = EMOTION_DICT.get(emotion_en, emotion_en)
                    
                    await websocket.send_text(json.dumps({
                        "status": "emotion_result",
                        "emotion": detected_emotion
                    }))
                except Exception:
                    continue 
            #-----------------ãƒãƒ£ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†------------------
            elif data["type"]=="chat":
                response_json=make_response(data,detected_emotion)
                # ãƒ–ãƒ©ã‚¦ã‚¶ã«è¿”ç­”ã‚’é€ä¿¡
                await websocket.send_text(json.dumps({
                    "status":"chat_response",
                    "reply":response_json["reply"],
                    "ai_emotion":response_json["ai_emotion"]
                }))
    except Exception as e:
        print(f"Disconnected: {e}")

#é€šä¿¡ãŒå§‹ã¾ã£ãŸç¬é–“ã®é€šä¿¡,ä¸€å›ç›®ã®é¡”å†™çœŸã®å—ä¿¡ã®éš›ã«ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸè¨­å®šã‚’è¡Œã†é–¢æ•°
def first_contact(raw_data):
    global chat_history
    data = json.loads(raw_data)
    if data["type"]=="image":
        encoded_data = data["value"].split(',')[1]
        nparr = np.frombuffer(base64.b64decode(encoded_data), np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        results = DeepFace.analyze(frame, actions=['age','gender','race'], enforce_detection=False)
        user_age = results[0]['age']
        user_gender=results[0]['gender']
        user_race=results[0]['race']
        print(f"User info - Age: {user_age}, Gender: {user_gender}, Race    : {user_race}")

        #ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦
        user_content = (
                    "ã‚ãªãŸãŒä»Šä¼šè©±ã‚’ã—ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚ãªãŸã¨ä»²ã®è‰¯ã„å‹äººã§ã‚ã‚Šã€æƒ…å ±ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n"
                    f"å¹´é½¢:{user_age}æ­³ã€æ€§:{user_gender}ã€äººç¨®:{user_race}\n"
                    )
        f=open('static/character/ai_profile.txt','r',encoding='utf-8')
        ai_content=f.read()
        f.close()

        #chat_historyã®å±¥æ­´ã«æœ€åˆã®åˆæœŸè¨­å®šã‚’è¿½åŠ 
        chat_history.append({"role": "system","content":ai_content})
        chat_history.append({"role": "user", "content": user_content})


#ãƒãƒ£ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®è¿”ä¿¡
def make_response(data,now_emotion):
    global chat_history
    user_message=data["value"]
    #ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜
    chat_history.append({"role":"user","content":f"è¡¨æƒ…:{now_emotion} {user_message}"})
    print(f"Chat message received: {user_message}")
    
    # OpenAIç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦
    prompt = (
                f"ç›¸æ‰‹ã¯ä»Šã€Œ{now_emotion}ã€ã¨ã„ã†è¡¨æƒ…ã‚’ã—ã¦ã„ã¾ã™ã€‚\n"
                f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼š{user_message}\n"
                "ä¼šè©±ã®æµã‚Œã‚’ã‚¹ãƒ ãƒ¼ã‚ºã«ã™ã‚‹ãŸã‚è¿”ç­”ã®ç”Ÿæˆã¯ã§ãã‚‹ã ã‘æ—©ãè¡Œã£ã¦ãã ã•ã„ã€‚\n"
                "ã¾ãŸã€è©±ã—è¨€è‘‰ã‚’æƒ³å®šã—ç®‡æ¡æ›¸ããªã©ã¯æ§ãˆã€30å­—ä»¥å†…ã«æŠ‘ãˆã¦ãã ã•ã„\n"
                "ä»¥ä¸‹ã®JSONå½¢å¼ã§è¿”ç­”ã—ã¦ãã ã•ã„ï¼š\n"
                "{ \"reply\": \"30å­—ä»¥å†…ã®è¿”ç­”\", \"ai_emotion\": \"å–œã³/æ‚²ã—ã¿/é©šã/è‡ªç„¶ä½“/æ€’ã‚Š/å«Œæ‚ª/æã‚Œ\" }\n" 
            )
    
    current_messages = chat_history + [{"role": "user", "content": prompt}]

    # OpenAI APIã‚’å‘¼ã³å‡ºã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=current_messages,#ã“ã®æ™‚å±¥æ­´ã‚‚ä¸€ç·’ã«æ¸¡ã™
        response_format={"type": "json_object"}
    )
    
    response_json=json.loads(response.choices[0].message.content)
    print(f"AI Response: {response_json}")
    #chat_historyã®æ›´æ–°
    chat_history.append({"role":"assistant","content":response_json["reply"]})
    # å±¥æ­´ãŒé•·ããªã‚Šã™ãã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã§ã€åˆæœŸè¨­å®šã¯æ®‹ã—ã¦ç›´è¿‘10ä»¶ãã‚‰ã„ã«çµã‚‹ã®ãŒä¸€èˆ¬çš„
    if len(chat_history) > 11:
        chat_history = [chat_history[0]] +[chat_history[1]] + chat_history[-10:]
    return response_json


# pythonã‚µãƒ¼ãƒã®ç«‹ã¡ä¸Šã’
if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)